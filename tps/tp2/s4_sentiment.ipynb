{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis \n",
    "\n",
    "## 1. Textblob-FR\n",
    "\n",
    "Documentation: https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation de la fonction `get_sentiment` pour return les valeurs des sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "def get_sentiment(input_text):\n",
    "    blob = tb(input_text)\n",
    "    polarity, subjectivity = blob.sentiment\n",
    "    polarity_perc = 100 * abs(polarity)\n",
    "    subjectivity_perc = 100 * subjectivity\n",
    "\n",
    "    # Polarité : positif / négatif / neutre\n",
    "    if polarity > 0:\n",
    "        polarity_str = f\"{polarity_perc:.0f}% positive\"\n",
    "        polarity_label = \"Positive\"\n",
    "    elif polarity < 0:\n",
    "        polarity_str = f\"{polarity_perc:.0f}% negative\"\n",
    "        polarity_label = \"Négative\"\n",
    "    else:\n",
    "        polarity_str = \"Neutre\"\n",
    "        polarity_label = \"Neutre\"\n",
    "\n",
    "    # Subjectivité\n",
    "    if subjectivity > 0:\n",
    "        subjectivity_str = f\"{subjectivity_perc:.0f}% subjective\"\n",
    "    else:\n",
    "        subjectivity_str = \"Parfaitement objective\"\n",
    "\n",
    "    # → on retourne un dictionnaire (pour un DataFrame)\n",
    "    return {\n",
    "        \"Texte\": input_text,\n",
    "        \"Polarité\": polarity,\n",
    "        \"Polarité (%)\": f\"{polarity_perc:.0f}%\",\n",
    "        \"Tonalité\": polarity_label,\n",
    "        \"Détail polarité\": polarity_str,\n",
    "        \"Subjectivité\": subjectivity,\n",
    "        \"Subjectivité (%)\": f\"{subjectivity_perc:.0f}%\",\n",
    "        \"Détail subjectivité\": subjectivity_str\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser le sentiment de 10 phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choisir 10 phrases au hasard\n",
    "\n",
    "phrase1 = \"Etienne Debel (né à Iseghem, trente- quatre ans, visage ouvert, parfait bilingue) avait commencé une carrière de comédien au Théâtre national d’expression flamande\"\n",
    "\n",
    "phrase2 = (\n",
    "    \"Puis, à vingt-quatre ans, il crée sa propre compagnie (• Het Vlaamse Schouwtoneel •) pour laquelle il signe quelque vingt mises en scène et qu’il emmène en tournée, \"\n",
    "    \"notamment en Allemagne, en Hollande et au Congo\"\n",
    ")\n",
    "\n",
    "phrase3 = (\n",
    "    \"Un jour, ce jeune aventurier du théâtre, passionné par les pièces les plus ambitieuses mais aussi par la découverte des auteurs nationaux, décide de créer (avant qu’aucune troupe d’expression française n'y ait songé) \"\n",
    "    \"* Èliezer et Sarah », une pièce de notre compatriote Marcel Falmagne\"\n",
    ")\n",
    "\n",
    "phrase4 = \"L'action se passe en Israël, dans un kibboutz, c'est-à-dire une ferme collective, et il fallait que des Tel-Aviv, et l’qxitre * Victor ou les enfants au pàxivoir », de Roger Vitrac, en province\"\n",
    "\n",
    "phrase5 = (\n",
    "    \"Et on compte encore, à Tel-Aviv, le théâtre Ha- caxneri qui donne, entre autres, des comédies mxisicales israéliennes (ou « My Fait Lady », qui a fait salle comble pendant un an), plus le théâtre Zavit, \"\n",
    "    \"avec deux troxipes également, le théâtre des Saisons, dirigé par le jeune auteur israélien Aloni qui vaxit, poxir moi, Ioxxesco et Beckett, plus des tas de jeunes compagnies professionnelles (dont l’xtne a joué < Les Chaises », d’Ionesco pendaxxt cinq ans)\"\n",
    ")\n",
    "\n",
    "phrase6 = \"Saxxs compter les théâtres de boxilevard... — \"\n",
    "\n",
    "phrase7 = \"C'est évidemment une activité assez prodigiexise poxir une ville de... — Huit cent mille habitants\" \n",
    "\n",
    "phrase8 = \"Mais tout bouge sur le plan artistique en Israël\" \n",
    "\n",
    "phrase9 = \"Il xj a xm théâtre mxinicipal à Haïffa\" \n",
    "\n",
    "phrase10 = \"Il faudrait que soit bien amer, le spectateur qui se déclarerait déçu d’un spectacle où le « mort » même ne manque pas d’esprit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Texte  Polarité Polarité (%)  \\\n",
      "0  Etienne Debel (né à Iseghem, trente- quatre an...  0.370000          37%   \n",
      "1  Puis, à vingt-quatre ans, il crée sa propre co...  0.330000          33%   \n",
      "2  Un jour, ce jeune aventurier du théâtre, passi...  0.261667          26%   \n",
      "3  L'action se passe en Israël, dans un kibboutz,...  0.225000          22%   \n",
      "4  Et on compte encore, à Tel-Aviv, le théâtre Ha...  0.155000          16%   \n",
      "5     Saxxs compter les théâtres de boxilevard... —   0.000000           0%   \n",
      "6  C'est évidemment une activité assez prodigiexi...  0.200000          20%   \n",
      "7   Mais tout bouge sur le plan artistique en Israël  0.160000          16%   \n",
      "8             Il xj a xm théâtre mxinicipal à Haïffa  0.000000           0%   \n",
      "9  Il faudrait que soit bien amer, le spectateur ... -0.400000          40%   \n",
      "\n",
      "   Tonalité Détail polarité  Subjectivité Subjectivité (%)  \\\n",
      "0  Positive    37% positive       0.30000              30%   \n",
      "1  Positive    33% positive       0.20000              20%   \n",
      "2  Positive    26% positive       0.25000              25%   \n",
      "3  Positive    22% positive       0.15000              15%   \n",
      "4  Positive    16% positive       0.19375              19%   \n",
      "5    Neutre          Neutre       0.00000               0%   \n",
      "6  Positive    20% positive       0.40000              40%   \n",
      "7  Positive    16% positive       0.15000              15%   \n",
      "8    Neutre          Neutre       0.00000               0%   \n",
      "9  Négative    40% negative       0.55000              55%   \n",
      "\n",
      "      Détail subjectivité  \n",
      "0          30% subjective  \n",
      "1          20% subjective  \n",
      "2          25% subjective  \n",
      "3          15% subjective  \n",
      "4          19% subjective  \n",
      "5  Parfaitement objective  \n",
      "6          40% subjective  \n",
      "7          15% subjective  \n",
      "8  Parfaitement objective  \n",
      "9          55% subjective  \n"
     ]
    }
   ],
   "source": [
    "# Créer une liste des phrases\n",
    "phrases = [phrase1, phrase2, phrase3, phrase4, phrase5, phrase6, phrase7, phrase8, phrase9, phrase10]\n",
    "\n",
    "# Boucle sur les phrases\n",
    "resultats = [get_sentiment(p) for p in phrases]\n",
    "\n",
    "# Création du DataFrame\n",
    "df_sentiments = pd.DataFrame(resultats)\n",
    "\n",
    "# Affichage du tableau complet\n",
    "print(df_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is 41% negative and 60% subjective.\n"
     ]
    }
   ],
   "source": [
    "get_sentiment(\"Cette phrase est négative et je ne suis pas content !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utilisation de transformers\n",
    "\n",
    "Documentation: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert\n",
    "\n",
    "**!!** Si le code ne tourne pas sur votre machine, vous pouvez le tester directement sur Google Colab en utilisant [ce lien](https://colab.research.google.com/github/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/colab/french_sentiment_analysis_with_bert.ipynb) **!!**\n",
    "\n",
    "Le modèle peut également être testé en ligne sur [HuggingFace](https://huggingface.co/tblard/tf-allocine)\n",
    "\n",
    "### Installation des librairies et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow) (1.26.0)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp311-cp311-win_amd64.whl (331.8 MB)\n",
      "   ---------------------------------------- 331.8/331.8 MB 3.6 MB/s  0:01:24\n",
      "Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 4.7/4.7 MB 4.8 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp311-cp311-win_amd64.whl (206 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.3 MB/s  0:00:01\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 2.9/2.9 MB 4.8 MB/s  0:00:00\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 1.4/1.4 MB 5.3 MB/s  0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 26.4/26.4 MB 4.6 MB/s  0:00:05\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.0-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp311-cp311-win_amd64.whl (313 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.33.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 1.1/1.1 MB 4.6 MB/s  0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 12.0/12.0 MB 4.6 MB/s  0:00:02\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 564.3/564.3 kB 6.6 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.3 MB/s  0:00:00\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.9.0 huggingface-hub-0.35.3 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tf_keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tf_keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (1.26.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf_keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf_keras) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf_keras) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf_keras) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf_keras) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf_keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf_keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf_keras) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf_keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf_keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf_keras) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf_keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf_keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tommy\\tac2\\tac\\tac_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf_keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.5 MB/s  0:00:00\n",
      "Installing collected packages: tf_keras\n",
      "Successfully installed tf_keras-2.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install sentencepiece\n",
    "%pip install transformers\n",
    "%pip install tf_keras\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mtblard/tf-allocine\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m model = TFAutoModelForSequenceClassification.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mtblard/tf-allocine\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m sentiment_analyser = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tommy\\TAC2\\TAC\\tac_venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1017\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1012\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1013\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mYou cannot use both `pipeline(... dtype=..., model_kwargs=\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:...})` as those\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1014\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m arguments might conflict, use only one.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1015\u001b[39m         )\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m, dtype):\n\u001b[32m   1018\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(torch, dtype)\n\u001b[32m   1019\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m] = dtype\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\", use_pt=False)\n",
    "#model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
    "\n",
    "#sentiment_analyser = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "#proposition de correction de GPT\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n",
    "\n",
    "sentiment_analyser = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser le sentiment d'une phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyser(\"Ce journal est vraiment super intéressant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyser(\"Cette phrase est négative et je ne suis pas content !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac_venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
